{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_yolov5_train_bccd_15.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejrtks1020/Computer_Vision_2/blob/main/CV_yolov5_train_bccd_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqMcg3Hb2N3Y"
      },
      "source": [
        "### Yolo v5 다운로드 및 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CwoCtHOZnPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1933c4-3e3c-4d95-c3e5-2badc0e00aa5"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!cd yolov5;pip install -qr requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10344, done.\u001b[K\n",
            "remote: Total 10344 (delta 0), reused 0 (delta 0), pack-reused 10344\u001b[K\n",
            "Receiving objects: 100% (10344/10344), 10.59 MiB | 25.87 MiB/s, done.\n",
            "Resolving deltas: 100% (7143/7143), done.\n",
            "\u001b[K     |████████████████████████████████| 596 kB 14.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIMUxsDb7QJO"
      },
      "source": [
        "### XML 포맷의 BCCD 데이터 세트를 다운로드 후 voc2coco를 이용하여 ms-coco 형태로 변환. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsJhDrXFg2kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babf9bfc-b006-47c6-ea39-e4ee9b1d2a8a"
      },
      "source": [
        "import os\n",
        "\n",
        "!git clone https://github.com/Shenggan/BCCD_Dataset.git\n",
        "!git clone https://github.com/yukkyo/voc2coco.git\n",
        "\n",
        "# colab 버전은 아래 명령어로 BCCD의 labels.txt를 생성합니다.  \n",
        "with open('/content/BCCD_Dataset/BCCD/labels.txt', \"w\") as f:\n",
        "    f.write(\"WBC\\n\")\n",
        "    f.write(\"RBC\\n\")\n",
        "    f.write(\"Platelets\\n\")\n",
        "\n",
        "!cat /content/BCCD_Dataset/BCCD/labels.txt\n",
        "\n",
        "# VOC를 COCO로 변환 수행. 학습/검증/테스트 용 json annotation을 생성. \n",
        "%cd voc2coco\n",
        "!python voc2coco.py --ann_dir /content/BCCD_Dataset/BCCD/Annotations \\\n",
        "--ann_ids /content/BCCD_Dataset/BCCD/ImageSets/Main/train.txt \\\n",
        "--labels /content/BCCD_Dataset/BCCD/labels.txt \\\n",
        "--output /content/BCCD_Dataset/BCCD/train.json \\\n",
        "--ext xml\n",
        "\n",
        "!python voc2coco.py --ann_dir /content/BCCD_Dataset/BCCD/Annotations \\\n",
        "--ann_ids /content/BCCD_Dataset/BCCD/ImageSets/Main/val.txt \\\n",
        "--labels /content/BCCD_Dataset/BCCD/labels.txt \\\n",
        "--output /content/BCCD_Dataset/BCCD/val.json \\\n",
        "--ext xml\n",
        "\n",
        "!python voc2coco.py --ann_dir /content/BCCD_Dataset/BCCD/Annotations \\\n",
        "--ann_ids /content/BCCD_Dataset/BCCD/ImageSets/Main/test.txt \\\n",
        "--labels /content/BCCD_Dataset/BCCD/labels.txt \\\n",
        "--output /content/BCCD_Dataset/BCCD/test.json \\\n",
        "--ext xml\n",
        "\n",
        "# annotation json 파일을 잘 볼수 있는 jq 유틸리티 셋업. \n",
        "!sudo apt-get install jq\n",
        "!jq . /content/BCCD_Dataset/BCCD/train.json > output.json\n",
        "!tail -100 output.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BCCD_Dataset'...\n",
            "remote: Enumerating objects: 800, done.\u001b[K\n",
            "remote: Total 800 (delta 0), reused 0 (delta 0), pack-reused 800\u001b[K\n",
            "Receiving objects: 100% (800/800), 7.39 MiB | 24.80 MiB/s, done.\n",
            "Resolving deltas: 100% (378/378), done.\n",
            "Cloning into 'voc2coco'...\n",
            "remote: Enumerating objects: 423, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 423 (delta 3), reused 9 (delta 3), pack-reused 409\u001b[K\n",
            "Receiving objects: 100% (423/423), 214.64 KiB | 7.67 MiB/s, done.\n",
            "Resolving deltas: 100% (379/379), done.\n",
            "WBC\n",
            "RBC\n",
            "Platelets\n",
            "/content/voc2coco\n",
            "Start converting !\n",
            "100% 205/205 [00:00<00:00, 5074.10it/s]\n",
            "Start converting !\n",
            "100% 87/87 [00:00<00:00, 5644.83it/s]\n",
            "Start converting !\n",
            "100% 72/72 [00:00<00:00, 5559.36it/s]\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libjq1 libonig4\n",
            "The following NEW packages will be installed:\n",
            "  jq libjq1 libonig4\n",
            "0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 276 kB of archives.\n",
            "After this operation, 930 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libonig4 amd64 6.7.0-1 [119 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjq1 amd64 1.5+dfsg-2 [111 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 jq amd64 1.5+dfsg-2 [45.6 kB]\n",
            "Fetched 276 kB in 0s (2,993 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libonig4:amd64.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../libonig4_6.7.0-1_amd64.deb ...\n",
            "Unpacking libonig4:amd64 (6.7.0-1) ...\n",
            "Selecting previously unselected package libjq1:amd64.\n",
            "Preparing to unpack .../libjq1_1.5+dfsg-2_amd64.deb ...\n",
            "Unpacking libjq1:amd64 (1.5+dfsg-2) ...\n",
            "Selecting previously unselected package jq.\n",
            "Preparing to unpack .../jq_1.5+dfsg-2_amd64.deb ...\n",
            "Unpacking jq (1.5+dfsg-2) ...\n",
            "Setting up libonig4:amd64 (6.7.0-1) ...\n",
            "Setting up libjq1:amd64 (1.5+dfsg-2) ...\n",
            "Setting up jq (1.5+dfsg-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "      \"category_id\": 2,\n",
            "      \"ignore\": 0,\n",
            "      \"segmentation\": [],\n",
            "      \"image_id\": \"BloodImage_00408\",\n",
            "      \"id\": 2800\n",
            "    },\n",
            "    {\n",
            "      \"area\": 9405,\n",
            "      \"iscrowd\": 0,\n",
            "      \"bbox\": [\n",
            "        102,\n",
            "        0,\n",
            "        99,\n",
            "        95\n",
            "      ],\n",
            "      \"category_id\": 2,\n",
            "      \"ignore\": 0,\n",
            "      \"segmentation\": [],\n",
            "      \"image_id\": \"BloodImage_00408\",\n",
            "      \"id\": 2801\n",
            "    },\n",
            "    {\n",
            "      \"area\": 7128,\n",
            "      \"iscrowd\": 0,\n",
            "      \"bbox\": [\n",
            "        197,\n",
            "        0,\n",
            "        88,\n",
            "        81\n",
            "      ],\n",
            "      \"category_id\": 2,\n",
            "      \"ignore\": 0,\n",
            "      \"segmentation\": [],\n",
            "      \"image_id\": \"BloodImage_00408\",\n",
            "      \"id\": 2802\n",
            "    },\n",
            "    {\n",
            "      \"area\": 756,\n",
            "      \"iscrowd\": 0,\n",
            "      \"bbox\": [\n",
            "        0,\n",
            "        280,\n",
            "        21,\n",
            "        36\n",
            "      ],\n",
            "      \"category_id\": 3,\n",
            "      \"ignore\": 0,\n",
            "      \"segmentation\": [],\n",
            "      \"image_id\": \"BloodImage_00408\",\n",
            "      \"id\": 2803\n",
            "    },\n",
            "    {\n",
            "      \"area\": 1302,\n",
            "      \"iscrowd\": 0,\n",
            "      \"bbox\": [\n",
            "        382,\n",
            "        253,\n",
            "        42,\n",
            "        31\n",
            "      ],\n",
            "      \"category_id\": 3,\n",
            "      \"ignore\": 0,\n",
            "      \"segmentation\": [],\n",
            "      \"image_id\": \"BloodImage_00408\",\n",
            "      \"id\": 2804\n",
            "    },\n",
            "    {\n",
            "      \"area\": 42120,\n",
            "      \"iscrowd\": 0,\n",
            "      \"bbox\": [\n",
            "        309,\n",
            "        318,\n",
            "        260,\n",
            "        162\n",
            "      ],\n",
            "      \"category_id\": 1,\n",
            "      \"ignore\": 0,\n",
            "      \"segmentation\": [],\n",
            "      \"image_id\": \"BloodImage_00408\",\n",
            "      \"id\": 2805\n",
            "    }\n",
            "  ],\n",
            "  \"categories\": [\n",
            "    {\n",
            "      \"supercategory\": \"none\",\n",
            "      \"id\": 1,\n",
            "      \"name\": \"WBC\"\n",
            "    },\n",
            "    {\n",
            "      \"supercategory\": \"none\",\n",
            "      \"id\": 2,\n",
            "      \"name\": \"RBC\"\n",
            "    },\n",
            "    {\n",
            "      \"supercategory\": \"none\",\n",
            "      \"id\": 3,\n",
            "      \"name\": \"Platelets\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o0rtihpKL3F"
      },
      "source": [
        "!head -100 output.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXDKxJ6PhjFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73da1f3-2b5d-4d75-c4eb-5d4b4208e1f7"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM2Ug9A5KuJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e437b0-275e-45f9-cce1-b36deea4a214"
      },
      "source": [
        "!git clone https://github.com/alexmihalyk23/COCO2YOLO.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COCO2YOLO'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 63 (delta 25), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY7tHwgh7rR3"
      },
      "source": [
        "### COCO 포맷을 Ultralytics yolo 포맷으로 변환\n",
        "* https://github.com/alexmihalyk23/COCO2YOLO.git 를 약간 수정하여 변환로직 생성.\n",
        "* 소스 이미지 디렉토리와 Json annotation 파일, 타겟 이미지 디렉토리, 타겟 annotation 디렉토리를 기반으로 train/val/test Json annotation 파일에 따라 소스 이미지 디렉토리에 있는 파일들은 타겟 이미지 디렉토리로 단순 복사하고, annotation 파일은 yolo 포맷으로 변환하여 타겟 annotation 디렉토리로 저장\n",
        "* 한개의 json annotation 파일이 여러개의 yolo 포맷 annotation 파일로 변환됨. \n",
        "* Ultralytics 도 JSON2Yolo 를 제공하나, 적용 시 coco dataset의 customization이 별도 필요. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8ePJQO7MWD-"
      },
      "source": [
        "# https://github.com/alexmihalyk23/COCO2YOLO.git\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "class COCO2YOLO:\n",
        "  # 소스 이미지 디렉토리와 Json annotation 파일, 타겟 이미지 디렉토리, 타겟 annotation 디렉토리를 생성자로 입력 받음. \n",
        "  def __init__(self, src_img_dir, json_file, tgt_img_dir, tgt_anno_dir):\n",
        "    self.json_file = json_file\n",
        "    self.src_img_dir = src_img_dir\n",
        "    self.tgt_img_dir = tgt_img_dir\n",
        "    self.tgt_anno_dir = tgt_anno_dir\n",
        "    # json 파일과 타겟 디렉토리가 존재하는지 확인하고, 디렉토리의 경우는 없으면 생성. \n",
        "    self._check_file_and_dir(json_file, tgt_img_dir, tgt_anno_dir)\n",
        "    # json 파일을 메모리로 로딩. \n",
        "    self.labels = json.load(open(json_file, 'r', encoding='utf-8'))\n",
        "    # category id와 이름을 매핑하지만, 실제 class id는 이를 적용하지 않고 별도 적용. \n",
        "    self.coco_id_name_map = self._categories()\n",
        "    self.coco_name_list = list(self.coco_id_name_map.values())\n",
        "    print(\"total images\", len(self.labels['images']))\n",
        "    print(\"total categories\", len(self.labels['categories']))\n",
        "    print(\"total labels\", len(self.labels['annotations']))\n",
        "  \n",
        "  # json 파일과 타겟 디렉토리가 존재하는지 확인하고, 디렉토리의 경우는 없으면 생성. \n",
        "  def _check_file_and_dir(self, file_path, tgt_img_dir, tgt_anno_dir):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise ValueError(\"file not found\")\n",
        "    if not os.path.exists(tgt_img_dir):\n",
        "        os.makedirs(tgt_img_dir)\n",
        "    if not os.path.exists(tgt_anno_dir):\n",
        "        os.makedirs(tgt_anno_dir)\n",
        "\n",
        "  # category id와 이름을 매핑하지만, 추후에 class 명만 활용. \n",
        "  def _categories(self):\n",
        "    categories = {}\n",
        "    for cls in self.labels['categories']:\n",
        "        categories[cls['id']] = cls['name']\n",
        "    return categories\n",
        "  \n",
        "  # annotation에서 모든 image의 파일명(절대 경로 아님)과 width, height 정보 저장. \n",
        "  def _load_images_info(self):\n",
        "    images_info = {}\n",
        "    for image in self.labels['images']:\n",
        "        id = image['id']\n",
        "        file_name = image['file_name']\n",
        "        if file_name.find('\\\\') > -1:\n",
        "            file_name = file_name[file_name.index('\\\\')+1:]\n",
        "        w = image['width']\n",
        "        h = image['height']\n",
        "  \n",
        "        images_info[id] = (file_name, w, h)\n",
        "\n",
        "    return images_info\n",
        "\n",
        "  # ms-coco의 bbox annotation은 yolo format으로 변환. 좌상단 x, y좌표, width, height 기반을 정규화된 center x,y 와 width, height로 변환. \n",
        "  def _bbox_2_yolo(self, bbox, img_w, img_h):\n",
        "    # ms-coco는 좌상단 x, y좌표, width, height\n",
        "    x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
        "    # center x좌표는 좌상단 x좌표에서 width의 절반을 더함. center y좌표는 좌상단 y좌표에서 height의 절반을 더함.  \n",
        "    centerx = bbox[0] + w / 2\n",
        "    centery = bbox[1] + h / 2\n",
        "    # centerx, centery, width, height를 이미지의 width/height로 정규화. \n",
        "    dw = 1 / img_w\n",
        "    dh = 1 / img_h\n",
        "    centerx *= dw\n",
        "    w *= dw\n",
        "    centery *= dh\n",
        "    h *= dh\n",
        "    return centerx, centery, w, h\n",
        "  \n",
        "  # image와 annotation 정보를 기반으로 image명과 yolo annotation 정보 가공. \n",
        "  # 개별 image당 하나의 annotation 정보를 가지도록 변환. \n",
        "  def _convert_anno(self, images_info):\n",
        "    anno_dict = dict()\n",
        "    for anno in self.labels['annotations']:\n",
        "      bbox = anno['bbox']\n",
        "      image_id = anno['image_id']\n",
        "      category_id = anno['category_id']\n",
        "\n",
        "      image_info = images_info.get(image_id)\n",
        "      image_name = image_info[0]\n",
        "      img_w = image_info[1]\n",
        "      img_h = image_info[2]\n",
        "      yolo_box = self._bbox_2_yolo(bbox, img_w, img_h)\n",
        "\n",
        "      anno_info = (image_name, category_id, yolo_box)\n",
        "      anno_infos = anno_dict.get(image_id)\n",
        "      if not anno_infos:\n",
        "        anno_dict[image_id] = [anno_info]\n",
        "      else:\n",
        "        anno_infos.append(anno_info)\n",
        "        anno_dict[image_id] = anno_infos\n",
        "    return anno_dict\n",
        "\n",
        "  # class 명을 파일로 저장하는 로직. 사용하지 않음. \n",
        "  def save_classes(self):\n",
        "    sorted_classes = list(map(lambda x: x['name'], sorted(self.labels['categories'], key=lambda x: x['id'])))\n",
        "    print('coco names', sorted_classes)\n",
        "    with open('coco.names', 'w', encoding='utf-8') as f:\n",
        "      for cls in sorted_classes:\n",
        "          f.write(cls + '\\n')\n",
        "    f.close()\n",
        "  # _convert_anno(images_info)로 만들어진 anno 정보를 개별 yolo anno txt 파일로 생성하는 로직. \n",
        "  # coco2yolo()에서 anno_dict = self._convert_anno(images_info)로 만들어진 anno_dict를 _save_txt()에 입력하여 파일 생성\n",
        "  def _save_txt(self, anno_dict):\n",
        "    # 개별 image별로 소스 image는 타겟이미지 디렉토리로 복사하고, 개별 annotation을 타겟 anno 디렉토리로 생성. \n",
        "    for k, v in anno_dict.items():\n",
        "      # 소스와 타겟 파일의 절대 경로 생성. \n",
        "      src_img_filename = os.path.join(self.src_img_dir, v[0][0])\n",
        "      tgt_anno_filename = os.path.join(self.tgt_anno_dir,v[0][0].split(\".\")[0] + \".txt\")\n",
        "      #print('source image filename:', src_img_filename, 'target anno filename:', tgt_anno_filename)\n",
        "      # 이미지 파일의 경우 타겟 디렉토리로 단순 복사. \n",
        "      shutil.copy(src_img_filename, self.tgt_img_dir)\n",
        "      # 타겟 annotation 출력 파일명으로 classid, bbox 좌표를 object 별로 생성. \n",
        "      with open(tgt_anno_filename, 'w', encoding='utf-8') as f:\n",
        "        #print(k, v)\n",
        "        # 여러개의 object 별로 classid와 bbox 좌표를 생성. \n",
        "        for obj in v:\n",
        "          cat_name = self.coco_id_name_map.get(obj[1])\n",
        "          # category_id는 class 명에 따라 0부터 순차적으로 부여. \n",
        "          category_id = self.coco_name_list.index(cat_name)\n",
        "          #print('cat_name:', cat_name, 'category_id:', category_id)\n",
        "          box = ['{:.6f}'.format(x) for x in obj[2]]\n",
        "          box = ' '.join(box)\n",
        "          line = str(category_id) + ' ' + box\n",
        "          f.write(line + '\\n')\n",
        "\n",
        "  # ms-coco를 yolo format으로 변환. \n",
        "  def coco2yolo(self):\n",
        "    print(\"loading image info...\")\n",
        "    images_info = self._load_images_info()\n",
        "    print(\"loading done, total images\", len(images_info))\n",
        "\n",
        "    print(\"start converting...\")\n",
        "    anno_dict = self._convert_anno(images_info)\n",
        "    print(\"converting done, total labels\", len(anno_dict))\n",
        "\n",
        "    print(\"saving txt file...\")\n",
        "    self._save_txt(anno_dict)\n",
        "    print(\"saving done\")\n",
        "\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5NxtxuaN1oz"
      },
      "source": [
        "!jq . /content/BCCD_Dataset/BCCD/val.json > output_val.json\n",
        "!cat output_val.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ7hyNCKiiAZ"
      },
      "source": [
        "# 학습/검증/테스트용 images, labels 디렉토리 생성. \n",
        "!mkdir /content/bccd;\n",
        "!cd /content/bccd; mkdir images; mkdir labels;\n",
        "!cd /content/bccd/images; mkdir train; mkdir val; mkdir test\n",
        "!cd /content/bccd/labels; mkdir train; mkdir val; mkdir test"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHG5twLoiAur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfb8c9e-bc90-43d5-9513-219ddc8d1098"
      },
      "source": [
        "# train 용 yolo 데이터 세트 생성. \n",
        "train_yolo_converter = COCO2YOLO(src_img_dir='/content/BCCD_Dataset/BCCD/JPEGImages', json_file='/content/BCCD_Dataset/BCCD/train.json',\n",
        "                                 tgt_img_dir='/content/bccd/images/train', tgt_anno_dir='/content/bccd/labels/train')\n",
        "train_yolo_converter.coco2yolo()\n",
        "\n",
        "# val 용 yolo 데이터 세트 생성. \n",
        "val_yolo_converter = COCO2YOLO(src_img_dir='/content/BCCD_Dataset/BCCD/JPEGImages', json_file='/content/BCCD_Dataset/BCCD/val.json',\n",
        "                                 tgt_img_dir='/content/bccd/images/val', tgt_anno_dir='/content/bccd/labels/val')\n",
        "val_yolo_converter.coco2yolo()\n",
        "\n",
        "# test 용 yolo 데이터 세트 생성. \n",
        "test_yolo_converter = COCO2YOLO(src_img_dir='/content/BCCD_Dataset/BCCD/JPEGImages', json_file='/content/BCCD_Dataset/BCCD/test.json',\n",
        "                                 tgt_img_dir='/content/bccd/images/test', tgt_anno_dir='/content/bccd/labels/test')\n",
        "test_yolo_converter.coco2yolo()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total images 205\n",
            "total categories 3\n",
            "total labels 2805\n",
            "loading image info...\n",
            "loading done, total images 205\n",
            "start converting...\n",
            "converting done, total labels 205\n",
            "saving txt file...\n",
            "saving done\n",
            "total images 87\n",
            "total categories 3\n",
            "total labels 1138\n",
            "loading image info...\n",
            "loading done, total images 87\n",
            "start converting...\n",
            "converting done, total labels 87\n",
            "saving txt file...\n",
            "saving done\n",
            "total images 72\n",
            "total categories 3\n",
            "total labels 945\n",
            "loading image info...\n",
            "loading done, total images 72\n",
            "start converting...\n",
            "converting done, total labels 72\n",
            "saving txt file...\n",
            "saving done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cDgV03PBrjj"
      },
      "source": [
        "### Dataset용 yaml 파일을 생성하고 학습 수행\n",
        "* yolo v5는 모델이 yolov5s(small), yolov5m(middle), yolov5l(large), yolov5x(extra large)로 되어있음. weight 인자값으로 이들중 하나를 입력해 줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li4wV4W9iA0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6913bc0c-da56-4ef1-af33-a1ca7f777da0"
      },
      "source": [
        "!wget -O /content/bccd/bccd.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/bccd.yaml"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-30 18:20:52--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/bccd.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184 [text/plain]\n",
            "Saving to: ‘/content/bccd/bccd.yaml’\n",
            "\n",
            "\r/content/bccd/bccd.   0%[                    ]       0  --.-KB/s               \r/content/bccd/bccd. 100%[===================>]     184  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-30 18:20:53 (8.42 MB/s) - ‘/content/bccd/bccd.yaml’ saved [184/184]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqWGfAn2mI9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c283d8-63ab-4682-fe97-dcd374f25d23"
      },
      "source": [
        "# Google Drive 접근을 위한 Mount 적용. \n",
        "import os, sys \n",
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OufKe0qemJAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d04b0a2-6897-48c1-9103-0791304668d2"
      },
      "source": [
        "# soft link로 Google Drive Directory 연결. \n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive\n",
        "# Google Drive 밑에 Directory 생성. 이미 생성 되어 있을 시 오류 발생. \n",
        "!mkdir \"/mydrive/ultra_workdir\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 파일_001\n",
            "'Colab Notebooks'\n",
            "'Computer Organization and Architecture.pdf ( PDFDrive.com ).gdoc'\n",
            " CREP-15-CP26023-과제번호-학번.gdoc\n",
            " CREP-15-CP26023-HW#4-201524402.gdoc\n",
            "'CREP-15-CP26023-HW7-20 ㅡ   ㅠㅍ 1524402.gdoc'\n",
            " CREP-15-CP26023-HW7-201524402.gdoc\n",
            " DaCom_For5_ch7.pptx\n",
            " DaCom_For5_ch8.pptx\n",
            " hw3_보고서양식.docx\n",
            " hw3_보고서양식.gdoc\n",
            "'INC 리포트 Template의 사본 (1).gdoc'\n",
            "'INC 리포트 Template의 사본.gdoc'\n",
            " 이의제기신청서.pdf\n",
            " Pdf\n",
            " pet_work_dir\n",
            " PreviewFiles컴퓨터구조론8판.pdf\n",
            " 발표.txt\n",
            " ultra_workdir\n",
            " 이전노트북백업파일.zip\n",
            "mkdir: cannot create directory ‘/mydrive/ultra_workdir’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNmkMzDSmJDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79602ba7-a5ce-4cdc-b81b-56c8953ecae1"
      },
      "source": [
        "###  10번 미만 epoch는 좋은 성능이 안나옴. 최소 30번 이상 epoch 적용. large 모델 적용 시 batch size가 8보다 클 경우 colab에서 memory 부족 발생.\n",
        "### 혈소판의 경우 상대적으로 mAP:0.5~0.95 Detection 성능이 좋지 못함. 백혈구 만큼 학습데이터가 적은것도 이유지만, Object 사이즈가 상대적으로 작음.   \n",
        "!cd /content/yolov5; python train.py --img 640 --batch 8 --epochs 30 --data /content/bccd/bccd.yaml --weights yolov5l.pt \\\n",
        "                                     --project=/mydrive/ultra_workdir --name bccd --exist-ok "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=/content/bccd/bccd.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=/mydrive/ultra_workdir, name=bccd, exist_ok=True, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.0-159-gdb6ec66 torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /mydrive/ultra_workdir', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5l.pt to yolov5l.pt...\n",
            "100% 89.2M/89.2M [00:04<00:00, 21.1MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     43080  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 468 layers, 46149064 parameters, 46149064 gradients, 108.0 GFLOPs\n",
            "\n",
            "Transferred 607/613 items from yolov5l.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 101 weight, 104 weight (no decay), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/bccd/labels/train' images and labels...205 found, 0 missing, 0 empty, 0 corrupted: 100% 205/205 [00:00<00:00, 1766.27it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/bccd/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/bccd/labels/val' images and labels...87 found, 0 missing, 0 empty, 0 corrupted: 100% 87/87 [00:00<00:00, 1168.79it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/bccd/labels/val.cache\n",
            "Plotting labels to /mydrive/ultra_workdir/bccd/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.76 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/mydrive/ultra_workdir/bccd\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/29     5.28G    0.1076    0.1663   0.03997        98       640: 100% 26/26 [00:22<00:00,  1.18it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.94it/s]\n",
            "                 all         87       1138     0.0388     0.0988     0.0223    0.00421\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/29     5.28G   0.09349    0.1821   0.03545       110       640: 100% 26/26 [00:19<00:00,  1.36it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.85it/s]\n",
            "                 all         87       1138     0.0923      0.156     0.0696     0.0146\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/29     5.28G   0.08392    0.1807   0.03051       170       640: 100% 26/26 [00:19<00:00,  1.36it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.69it/s]\n",
            "                 all         87       1138      0.457      0.146      0.125     0.0302\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/29     5.28G    0.0738    0.1633   0.02519        73       640: 100% 26/26 [00:18<00:00,  1.40it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:03<00:00,  1.75it/s]\n",
            "                 all         87       1138      0.846      0.172      0.177     0.0626\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/29     5.28G   0.06408    0.1602   0.02009        79       640: 100% 26/26 [00:18<00:00,  1.40it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:02<00:00,  2.12it/s]\n",
            "                 all         87       1138      0.855      0.196      0.214     0.0786\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/29     5.28G   0.05622    0.1631    0.0166       139       640: 100% 26/26 [00:18<00:00,  1.40it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:02<00:00,  2.59it/s]\n",
            "                 all         87       1138      0.214      0.567      0.345      0.143\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/29     5.28G   0.05173    0.1674   0.01446       111       640: 100% 26/26 [00:18<00:00,  1.40it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:02<00:00,  2.76it/s]\n",
            "                 all         87       1138      0.514      0.669      0.594      0.273\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/29     5.28G   0.04897    0.1573   0.01356       155       640: 100% 26/26 [00:18<00:00,  1.39it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:02<00:00,  2.94it/s]\n",
            "                 all         87       1138      0.476      0.848      0.703      0.348\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/29     5.28G    0.0518    0.1527   0.01226       100       640: 100% 26/26 [00:18<00:00,  1.40it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:02<00:00,  2.94it/s]\n",
            "                 all         87       1138      0.416       0.62      0.549      0.181\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/29     5.28G   0.05094    0.1525   0.01151       111       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.16it/s]\n",
            "                 all         87       1138       0.56      0.709      0.626      0.294\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/29     5.28G   0.04974    0.1514   0.01063        85       640: 100% 26/26 [00:18<00:00,  1.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.22it/s]\n",
            "                 all         87       1138      0.527       0.79      0.687      0.351\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/29     5.28G   0.04854    0.1433  0.009319        65       640: 100% 26/26 [00:18<00:00,  1.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.17it/s]\n",
            "                 all         87       1138      0.506      0.738      0.615      0.273\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/29     5.28G   0.04804    0.1504  0.008047       131       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.27it/s]\n",
            "                 all         87       1138       0.59      0.832      0.759      0.435\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/29     5.28G   0.04695    0.1385  0.007175        99       640: 100% 26/26 [00:18<00:00,  1.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.22it/s]\n",
            "                 all         87       1138      0.386      0.764      0.592      0.233\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/29     5.28G   0.05089     0.147  0.006408        92       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.28it/s]\n",
            "                 all         87       1138      0.606      0.758      0.689      0.372\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/29     5.28G   0.04716    0.1334  0.006103        84       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.29it/s]\n",
            "                 all         87       1138      0.575      0.739      0.682      0.348\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/29     5.28G   0.04467    0.1411  0.005306       166       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.28it/s]\n",
            "                 all         87       1138      0.633       0.77       0.76      0.422\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/29     5.28G   0.04524    0.1415  0.004761       101       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.28it/s]\n",
            "                 all         87       1138      0.726      0.801       0.79      0.488\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/29     5.28G   0.04062    0.1427  0.004512       121       640: 100% 26/26 [00:18<00:00,  1.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.25it/s]\n",
            "                 all         87       1138      0.601       0.78      0.809      0.506\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/29     5.28G   0.04326    0.1347  0.004282        89       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.18it/s]\n",
            "                 all         87       1138      0.604      0.845      0.785      0.427\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/29     5.28G   0.04017    0.1375  0.004276       136       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.33it/s]\n",
            "                 all         87       1138      0.609      0.749      0.704      0.421\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/29     5.28G   0.04162    0.1391  0.004007        98       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.32it/s]\n",
            "                 all         87       1138      0.744      0.821      0.869       0.56\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/29     5.28G   0.04225    0.1391  0.003756       104       640: 100% 26/26 [00:18<00:00,  1.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.29it/s]\n",
            "                 all         87       1138      0.774      0.898      0.898      0.582\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/29     5.28G    0.0352    0.1354  0.003781        95       640: 100% 26/26 [00:18<00:00,  1.42it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.27it/s]\n",
            "                 all         87       1138      0.865      0.837      0.884      0.532\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/29     5.28G   0.03632    0.1401  0.003426       162       640: 100% 26/26 [00:18<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.29it/s]\n",
            "                 all         87       1138       0.83      0.874      0.898      0.564\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/29     5.28G   0.03431    0.1318  0.003238       172       640: 100% 26/26 [00:18<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.29it/s]\n",
            "                 all         87       1138      0.848      0.878      0.903      0.569\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/29     5.28G   0.03282    0.1357  0.003182       106       640: 100% 26/26 [00:18<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.35it/s]\n",
            "                 all         87       1138      0.867      0.847      0.896      0.597\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/29     5.28G   0.03354    0.1268  0.003057       150       640: 100% 26/26 [00:18<00:00,  1.41it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.28it/s]\n",
            "                 all         87       1138      0.868      0.876      0.905      0.598\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/29     5.28G   0.03192    0.1394  0.003026       124       640: 100% 26/26 [00:18<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.24it/s]\n",
            "                 all         87       1138      0.832       0.89      0.896      0.579\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/29     5.28G   0.03137    0.1279   0.00292        64       640: 100% 26/26 [00:18<00:00,  1.43it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:01<00:00,  3.30it/s]\n",
            "                 all         87       1138      0.863      0.887      0.905       0.61\n",
            "\n",
            "30 epochs completed in 0.197 hours.\n",
            "Optimizer stripped from /mydrive/ultra_workdir/bccd/weights/last.pt, 92.8MB\n",
            "Optimizer stripped from /mydrive/ultra_workdir/bccd/weights/best.pt, 92.8MB\n",
            "\n",
            "Validating /mydrive/ultra_workdir/bccd/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 367 layers, 46119048 parameters, 0 gradients, 107.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 6/6 [00:04<00:00,  1.32it/s]\n",
            "                 all         87       1138      0.864      0.881      0.905       0.61\n",
            "                 WBC         87         87      0.973          1      0.992      0.799\n",
            "                 RBC         87        968      0.781      0.824       0.88      0.604\n",
            "           Platelets         87         83      0.838      0.819      0.842      0.426\n",
            "Results saved to \u001b[1m/mydrive/ultra_workdir/bccd\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnMxfqHdIDQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5824cbd1-f129-4f98-cd3d-cc57a27989ae"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "anno_list = train_yolo_converter.labels['annotations']\n",
        "category_list = [x['category_id'] for x in anno_list]\n",
        "\n",
        "Counter(category_list)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 214, 2: 2382, 3: 209})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mykCHLU22MdC"
      },
      "source": [
        "### 단일 이미지 inference 수행 및 테스트 데이터 세트 evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryBbBGko30zJ"
      },
      "source": [
        "# image 파일 inference \n",
        "!cd /content/yolov5;python detect.py --source /content/bccd/images/test/BloodImage_00011.jpg \\\n",
        "                            --weights /mydrive/ultra_workdir/bccd/weights/best.pt --conf 0.2 \\\n",
        "                            --project=/content/data/output --name=run_image --exist-ok --line-thickness 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUQrr8R75XSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396d2775-9acc-4755-dba0-e159f29911ca"
      },
      "source": [
        "!cd /content/yolov5; python test.py --weights /mydrive/ultra_workdir/bccd/weights/best.pt  --data /content/bccd/bccd.yaml \\\n",
        "                           --project /content/data/output --name=test_result --exist-ok --img 640 --iou 0.65\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'test.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4yQPIn1aNzx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}