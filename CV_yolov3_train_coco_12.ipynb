{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yolov3_train_coco.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejrtks1020/Computer_Vision_2/blob/main/CV_yolov3_train_coco_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPvjfCWE2KFj"
      },
      "source": [
        "### Ultralytics Yolo v3 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "I_Ua0GO8Sa5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88af66da-ee79-4d8a-f31a-411c275fc110"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd yolov3;pip install -qr requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 9957, done.\u001b[K\n",
            "remote: Total 9957 (delta 0), reused 0 (delta 0), pack-reused 9957\u001b[K\n",
            "Receiving objects: 100% (9957/9957), 9.31 MiB | 13.50 MiB/s, done.\n",
            "Resolving deltas: 100% (6716/6716), done.\n",
            "\u001b[K     |████████████████████████████████| 596 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 49.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 70.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 68.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b1xaZlnSSa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66c8f6a-ab2d-45b8-c4bd-c4794f17e39e"
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.10.0+cu111 (Tesla P100-PCIE-16GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wuNsf3fL2kD"
      },
      "source": [
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQd5TmHMgxE"
      },
      "source": [
        "### wandb(weight and bias) 모듈을 설치\n",
        "* 먼저 Weight and Bias 웹사이트에 계정 생성 및 연계 후 train 작업이 필요할 수도 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKc9lL_oKCPJ"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2Hcsh1R5iB"
      },
      "source": [
        "%cd /content\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNIrsZHI0_tz"
      },
      "source": [
        "### Dataset Config와 Weight 파일의 상대 경로, 절대 경로\n",
        "* train.py의 data option값으로 Dataset config yaml 파일을 지정할 수 있으며, 파일명만 입력할 경우는 yolov3/data 디렉토리 아래에서 해당 파일을 찾음. 절대 경로로 입력할 경우 해당 경로에서 찾음. \n",
        "* weights option의 경우 파일명만 입력할 경우 yolov3 디렉토리에서 해당 파일을 찾음. 해당 파일이 없을 경우 자동으로 해당 파일을 https://github.com/ultralytics/yolov3/releases 에서 Download 함. 절대 경로를 입력한 경우 해당 경로에서 파일을 찾되 파일이 없으면 해당 경로로 자동 Download함. \n",
        "* weights 파일은 yolov3.pt, yolov3-tiny.pt, yolov3-spp.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfxF4g_3Zh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36db0237-19cc-4960-9cee-2b7a01bf6276"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* --data : 절대경로가 아니라면 yolov3/data에서 찾음\n",
        "* --weights : 절대경로가 아니라면 yolov3에서 찾음, 만약 ''으로 공란이라면 --cfg yolov3.yaml 컨픽으로 모델을 만들어줌\n",
        "* --nosave : epoch마다 weight파일을 save하지말고 마지막에만 save\n",
        "* --cache : 한번 이미지를 읽으면 캐시에 저장해서 다음번에 빨리 읽어옴 "
      ],
      "metadata": {
        "id": "XTkpb0dr8zMX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wPnWKNXMSa5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc4bf23-54f3-4468-bc76-0efc5f2c1d4d"
      },
      "source": [
        "!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-5-g9d0e1cf torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 32.1MB/s]\n",
            "Dataset autodownload success, saved to ../datasets\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt to yolov3.pt...\n",
            "100% 119M/119M [00:01<00:00, 122MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.3 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv3, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/coco128/labels/train2017' images and labels...128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 1988.68it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 295.19it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 138.10it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.4G   0.03594   0.05591   0.01035       250       640: 100% 8/8 [00:16<00:00,  2.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.18it/s]\n",
            "                 all        128        929      0.765       0.75      0.823      0.585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     15.3G   0.03491   0.05372  0.008718       219       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.19it/s]\n",
            "                 all        128        929       0.78      0.747      0.825      0.587\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     15.3G   0.03731   0.05619   0.01182       280       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.19it/s]\n",
            "                 all        128        929      0.763      0.761      0.827      0.588\n",
            "\n",
            "3 epochs completed in 0.017 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 124.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 124.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 156.1 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.21s/it]\n",
            "                 all        128        929      0.762      0.761      0.827      0.588\n",
            "              person        128        254      0.886      0.772      0.863      0.621\n",
            "             bicycle        128          6      0.743      0.667      0.723       0.47\n",
            "                 car        128         46      0.863      0.435      0.684      0.305\n",
            "          motorcycle        128          5      0.811          1      0.962      0.763\n",
            "            airplane        128          6      0.915          1      0.995      0.786\n",
            "                 bus        128          7          1      0.678      0.937      0.807\n",
            "               train        128          3          1      0.991      0.995      0.896\n",
            "               truck        128         12       0.73        0.5      0.619      0.419\n",
            "                boat        128          6      0.701        0.5      0.573      0.349\n",
            "       traffic light        128         14      0.971      0.429      0.572      0.299\n",
            "           stop sign        128          2       0.72          1      0.995      0.747\n",
            "               bench        128          9       0.78      0.787      0.832      0.487\n",
            "                bird        128         16      0.969          1      0.995      0.664\n",
            "                 cat        128          4      0.873          1      0.995      0.958\n",
            "                 dog        128          9       0.79          1      0.995      0.774\n",
            "               horse        128          2      0.705          1      0.995      0.697\n",
            "            elephant        128         17       0.95      0.882      0.943      0.784\n",
            "                bear        128          1      0.682          1      0.995      0.895\n",
            "               zebra        128          4      0.873          1      0.995      0.958\n",
            "             giraffe        128          9      0.944          1      0.995      0.733\n",
            "            backpack        128          6      0.783      0.667      0.754        0.5\n",
            "            umbrella        128         18      0.898      0.889      0.947       0.65\n",
            "             handbag        128         19      0.753      0.526      0.569      0.346\n",
            "                 tie        128          7      0.915      0.857      0.857        0.6\n",
            "            suitcase        128          4      0.878          1      0.995      0.722\n",
            "             frisbee        128          5      0.739        0.8      0.761      0.658\n",
            "                skis        128          1      0.709          1      0.995      0.497\n",
            "           snowboard        128          7      0.928      0.714      0.827       0.63\n",
            "         sports ball        128          6       0.68      0.667      0.708      0.433\n",
            "                kite        128         10      0.627        0.6      0.683      0.185\n",
            "        baseball bat        128          4      0.673          1      0.945      0.422\n",
            "      baseball glove        128          7      0.669      0.571      0.679      0.353\n",
            "          skateboard        128          5      0.751        0.6      0.766      0.431\n",
            "       tennis racket        128          7      0.868      0.714      0.718      0.372\n",
            "              bottle        128         18      0.774      0.763      0.769      0.503\n",
            "          wine glass        128         16      0.782      0.875      0.886      0.545\n",
            "                 cup        128         36      0.889      0.888      0.917      0.649\n",
            "                fork        128          6      0.693        0.5      0.714      0.448\n",
            "               knife        128         16      0.723      0.812      0.838      0.537\n",
            "               spoon        128         22       0.89      0.636      0.691      0.474\n",
            "                bowl        128         28      0.868      0.704      0.779      0.623\n",
            "              banana        128          1      0.786          1      0.995      0.597\n",
            "            sandwich        128          2     0.0989     0.0989      0.448      0.408\n",
            "              orange        128          4      0.542          1      0.995      0.713\n",
            "            broccoli        128         11      0.493      0.364      0.361      0.305\n",
            "              carrot        128         24      0.825      0.784      0.874      0.576\n",
            "             hot dog        128          2      0.565          1      0.995      0.995\n",
            "               pizza        128          5      0.899          1      0.995      0.771\n",
            "               donut        128         14      0.748          1      0.964      0.896\n",
            "                cake        128          4      0.713          1      0.995      0.908\n",
            "               chair        128         35      0.666      0.771      0.797       0.51\n",
            "               couch        128          6      0.712      0.667      0.792      0.598\n",
            "        potted plant        128         14      0.709      0.714      0.833      0.572\n",
            "                 bed        128          3          1      0.982      0.995      0.631\n",
            "        dining table        128         13      0.595      0.385      0.533       0.32\n",
            "              toilet        128          2       0.81          1      0.995      0.945\n",
            "                  tv        128          2      0.488          1      0.995      0.821\n",
            "              laptop        128          3      0.682      0.333       0.72       0.46\n",
            "               mouse        128          2          1          0      0.828      0.469\n",
            "              remote        128          8       0.85      0.625      0.752      0.628\n",
            "          cell phone        128          8      0.545      0.375      0.571      0.354\n",
            "           microwave        128          3      0.657          1      0.995      0.863\n",
            "                oven        128          5      0.536        0.6      0.615      0.466\n",
            "                sink        128          6      0.408      0.333      0.465      0.302\n",
            "        refrigerator        128          5       0.93        0.8      0.862      0.659\n",
            "                book        128         29      0.558      0.241      0.354      0.164\n",
            "               clock        128          9      0.947          1      0.995      0.778\n",
            "                vase        128          2      0.446          1      0.663      0.597\n",
            "            scissors        128          1      0.705          1      0.995     0.0995\n",
            "          teddy bear        128         21      0.852      0.551      0.915      0.588\n",
            "          toothbrush        128          5       0.91          1      0.995      0.789\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSXORZdEmvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f211c3ae-ae46-4668-f43c-b42fa27bd842"
      },
      "source": [
        "!cp /content/yolov3/data/coco128.yaml /content/coco128/coco128.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/coco128/coco128.yaml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf1hUSV6Myw9"
      },
      "source": [
        "### COCO128 데이터 디렉토리를 변경후 학습 수행\n",
        "* /content/data 아래에 coco128 데이터 download 후 unzip\n",
        "* coco128 디렉토리가 변경되었으므로 coco128.yaml 데이터도 변경 적용. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz37RavwxYE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5bec26-3508-4180-dacc-265b3fd69864"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf /content/coco128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "guG3eNgXSa56"
      },
      "source": [
        "# /content 디렉토리에 coco128.zip을 download하고 tmp.zip으로 이름 변경 후 압축 해제. \n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ./ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD-azX0i2m-Y"
      },
      "source": [
        "# /content/data 디렉토리에 coco128.zip을 download하고 압축 해제\n",
        "!mkdir /content/data\n",
        "!wget -O /content/data/coco128.zip https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
        "!cd /content/data; unzip coco128.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "b4hTenv2Sa59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5fbfb9-4cf2-4a45-e0f6-f632752a318f"
      },
      "source": [
        "!wget -O /content/data/coco128/coco128_renew.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
        "!cat /content/data/coco128/coco128_renew.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-29 16:31:09--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: ‘/content/data/coco128/coco128_renew.yaml’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/data/coco1 100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-29 16:31:09 (31.4 MB/s) - ‘/content/data/coco128/coco128_renew.yaml’ saved [1594/1594]\n",
            "\n",
            "# COCO 2017 dataset http://cocodataset.org - first 128 training images\n",
            "# Train command: python train.py --data coco128.yaml\n",
            "# Default dataset location is next to YOLOv3:\n",
            "#   /parent_folder\n",
            "#     /coco128\n",
            "#     /yolov3\n",
            "\n",
            "\n",
            "# download command/URL (optional)\n",
            "#download: https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
            "\n",
            "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
            "train: /content/data/coco128/images/train2017/  # 128 images\n",
            "val: /content/data/coco128/images/train2017/  # 128 images\n",
            "\n",
            "# number of classes\n",
            "nc: 80\n",
            "\n",
            "# class names\n",
            "names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
            "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
            "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
            "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
            "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
            "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
            "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
            "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
            "         'hair drier', 'toothbrush' ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkk2f09xWDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c852b48-f3f2-4a8a-917f-b64224cb12cf"
      },
      "source": [
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=/content/data/coco128/coco128_renew.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-5-g9d0e1cf torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.3 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv3, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017' images and labels...128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 2485.82it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 306.81it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:01<00:00, 122.76it/s]\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.4G   0.03594   0.05588   0.01035       250       640: 100% 8/8 [00:16<00:00,  2.09s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.19it/s]\n",
            "                 all        128        929      0.766      0.749      0.823      0.585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     15.3G   0.03491   0.05372  0.008717       219       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.19it/s]\n",
            "                 all        128        929       0.78      0.747      0.825      0.587\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     15.3G   0.03731   0.05617   0.01183       280       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.19it/s]\n",
            "                 all        128        929      0.761      0.761       0.83      0.588\n",
            "\n",
            "3 epochs completed in 0.017 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 124.4MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 124.4MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 156.1 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:05<00:00,  1.27s/it]\n",
            "                 all        128        929      0.762      0.761       0.83      0.588\n",
            "              person        128        254      0.887      0.774      0.863      0.621\n",
            "             bicycle        128          6      0.742      0.667      0.723       0.47\n",
            "                 car        128         46      0.862      0.435      0.684      0.306\n",
            "          motorcycle        128          5      0.811          1      0.962      0.763\n",
            "            airplane        128          6      0.915          1      0.995      0.786\n",
            "                 bus        128          7          1      0.678      0.937      0.807\n",
            "               train        128          3          1       0.99      0.995      0.896\n",
            "               truck        128         12       0.73        0.5      0.618      0.418\n",
            "                boat        128          6        0.7        0.5      0.575      0.335\n",
            "       traffic light        128         14       0.97      0.429      0.572      0.299\n",
            "           stop sign        128          2       0.72          1      0.995      0.747\n",
            "               bench        128          9       0.78       0.79      0.832      0.498\n",
            "                bird        128         16      0.969          1      0.995      0.664\n",
            "                 cat        128          4      0.873          1      0.995      0.958\n",
            "                 dog        128          9       0.79          1      0.995      0.774\n",
            "               horse        128          2      0.705          1      0.995      0.697\n",
            "            elephant        128         17       0.95      0.882      0.943      0.784\n",
            "                bear        128          1      0.682          1      0.995      0.895\n",
            "               zebra        128          4      0.873          1      0.995      0.958\n",
            "             giraffe        128          9      0.944          1      0.995      0.733\n",
            "            backpack        128          6      0.781      0.667      0.754        0.5\n",
            "            umbrella        128         18      0.898      0.889      0.947       0.65\n",
            "             handbag        128         19      0.752      0.526      0.568      0.346\n",
            "                 tie        128          7      0.915      0.857      0.857        0.6\n",
            "            suitcase        128          4      0.877          1      0.995      0.722\n",
            "             frisbee        128          5      0.739        0.8      0.761      0.658\n",
            "                skis        128          1       0.71          1      0.995      0.497\n",
            "           snowboard        128          7      0.928      0.714      0.827       0.63\n",
            "         sports ball        128          6      0.681      0.667      0.708      0.433\n",
            "                kite        128         10      0.626        0.6      0.683      0.185\n",
            "        baseball bat        128          4      0.673          1      0.945      0.422\n",
            "      baseball glove        128          7       0.67      0.571      0.679      0.353\n",
            "          skateboard        128          5      0.752        0.6      0.766      0.431\n",
            "       tennis racket        128          7      0.868      0.714      0.718      0.372\n",
            "              bottle        128         18      0.775      0.764      0.768      0.496\n",
            "          wine glass        128         16      0.782      0.875      0.886      0.545\n",
            "                 cup        128         36      0.889      0.888      0.918      0.649\n",
            "                fork        128          6      0.692        0.5      0.714      0.448\n",
            "               knife        128         16      0.723      0.812      0.838      0.537\n",
            "               spoon        128         22      0.889      0.636      0.691      0.474\n",
            "                bowl        128         28      0.868      0.703      0.779      0.623\n",
            "              banana        128          1      0.786          1      0.995      0.597\n",
            "            sandwich        128          2     0.0996     0.0996      0.448      0.408\n",
            "              orange        128          4      0.542          1      0.995      0.713\n",
            "            broccoli        128         11      0.492      0.364      0.361      0.305\n",
            "              carrot        128         24      0.825      0.784      0.874      0.576\n",
            "             hot dog        128          2      0.565          1      0.995      0.995\n",
            "               pizza        128          5      0.899          1      0.995      0.751\n",
            "               donut        128         14      0.748          1      0.964      0.907\n",
            "                cake        128          4      0.713          1      0.995      0.908\n",
            "               chair        128         35      0.667      0.771      0.796      0.509\n",
            "               couch        128          6      0.712      0.667      0.792      0.598\n",
            "        potted plant        128         14      0.709      0.714      0.833      0.572\n",
            "                 bed        128          3          1      0.982      0.995      0.631\n",
            "        dining table        128         13      0.595      0.385      0.536      0.323\n",
            "              toilet        128          2       0.81          1      0.995      0.945\n",
            "                  tv        128          2      0.488          1      0.995      0.821\n",
            "              laptop        128          3      0.688      0.333       0.72       0.46\n",
            "               mouse        128          2          1          0      0.995      0.502\n",
            "              remote        128          8       0.85      0.625      0.752      0.628\n",
            "          cell phone        128          8      0.545      0.375      0.571      0.354\n",
            "           microwave        128          3      0.657          1      0.995      0.863\n",
            "                oven        128          5      0.537        0.6      0.615      0.465\n",
            "                sink        128          6      0.408      0.333      0.465      0.302\n",
            "        refrigerator        128          5       0.93        0.8      0.858      0.656\n",
            "                book        128         29      0.557      0.241      0.354      0.163\n",
            "               clock        128          9      0.947          1      0.995      0.778\n",
            "                vase        128          2      0.446          1      0.663      0.597\n",
            "            scissors        128          1      0.705          1      0.995     0.0995\n",
            "          teddy bear        128         21      0.852       0.55      0.911       0.58\n",
            "          toothbrush        128          5       0.91          1      0.995      0.789\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMrSquxNMDre"
      },
      "source": [
        "### labels 디렉토리명을 변경하고 수행. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r047cg90Sa6P"
      },
      "source": [
        "# mv 디렉토리A 디렉토리B : 디렉토리 이름을 변경\n",
        "!mv /content/data/coco128/labels /content/data/coco128/labels_chg "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef12IcJkLtBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbd1e2a-0515-4ab2-a924-dbb36aebb643"
      },
      "source": [
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=/content/data/coco128/coco128_renew.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-5-g9d0e1cf torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.3 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv3, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017' images and labels...0 found, 128 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 4757.55it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: No labels found in /content/data/coco128/labels/train2017.cache. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Cache directory /content/data/coco128/labels is not writeable: [Errno 2] No such file or directory: '/content/data/coco128/labels/train2017.cache.npy'\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 625, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 522, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"train.py\", line 215, in train\n",
            "    prefix=colorstr('train: '), shuffle=True)\n",
            "  File \"/content/yolov3/utils/datasets.py\", line 110, in create_dataloader\n",
            "    prefix=prefix)\n",
            "  File \"/content/yolov3/utils/datasets.py\", line 432, in __init__\n",
            "    assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {HELP_URL}'\n",
            "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels in /content/data/coco128/labels/train2017.cache. Can not train without labels. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLkIb95lL_Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16418883-c85f-4df4-abbc-66e1724f109b"
      },
      "source": [
        "# 다시 원복후 학습\n",
        "!mv /content/data/coco128/labels_chg /content/data/coco128/labels \n",
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=/content/data/coco128/coco128_renew.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-5-g9d0e1cf torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv3 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.3 GFLOPs\n",
            "\n",
            "Transferred 439/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv3, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 321.18it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 128/128 [00:00<00:00, 129.32it/s]\n",
            "Plotting labels to runs/train/exp4/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     11.4G   0.03594   0.05589   0.01035       250       640: 100% 8/8 [00:16<00:00,  2.10s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.18it/s]\n",
            "                 all        128        929      0.766      0.749      0.823      0.585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     15.3G   0.03491   0.05372  0.008717       219       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.18it/s]\n",
            "                 all        128        929       0.78      0.747      0.825      0.587\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     15.3G   0.03731   0.05619   0.01182       280       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.18it/s]\n",
            "                 all        128        929      0.763      0.761      0.829      0.589\n",
            "\n",
            "3 epochs completed in 0.017 hours.\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 124.4MB\n",
            "Optimizer stripped from runs/train/exp4/weights/best.pt, 124.4MB\n",
            "\n",
            "Validating runs/train/exp4/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 156.1 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:04<00:00,  1.21s/it]\n",
            "                 all        128        929      0.762      0.761       0.83      0.588\n",
            "              person        128        254      0.887      0.774      0.863      0.621\n",
            "             bicycle        128          6      0.743      0.667      0.723       0.47\n",
            "                 car        128         46      0.863      0.435      0.684      0.305\n",
            "          motorcycle        128          5      0.811          1      0.962      0.763\n",
            "            airplane        128          6      0.915          1      0.995      0.786\n",
            "                 bus        128          7          1      0.678      0.937      0.807\n",
            "               train        128          3          1       0.99      0.995      0.896\n",
            "               truck        128         12       0.73        0.5      0.621       0.42\n",
            "                boat        128          6        0.7        0.5      0.573      0.349\n",
            "       traffic light        128         14      0.971      0.429      0.572        0.3\n",
            "           stop sign        128          2       0.72          1      0.995      0.747\n",
            "               bench        128          9       0.78       0.79      0.832      0.498\n",
            "                bird        128         16      0.969          1      0.995      0.664\n",
            "                 cat        128          4      0.873          1      0.995      0.958\n",
            "                 dog        128          9       0.79          1      0.995      0.774\n",
            "               horse        128          2      0.705          1      0.995      0.697\n",
            "            elephant        128         17      0.951      0.882      0.943      0.784\n",
            "                bear        128          1      0.682          1      0.995      0.895\n",
            "               zebra        128          4      0.873          1      0.995      0.958\n",
            "             giraffe        128          9      0.944          1      0.995      0.733\n",
            "            backpack        128          6      0.781      0.667      0.754        0.5\n",
            "            umbrella        128         18      0.898      0.889      0.947       0.65\n",
            "             handbag        128         19      0.752      0.526      0.568      0.346\n",
            "                 tie        128          7      0.915      0.857      0.857        0.6\n",
            "            suitcase        128          4      0.878          1      0.995      0.722\n",
            "             frisbee        128          5      0.739        0.8      0.761      0.658\n",
            "                skis        128          1      0.709          1      0.995      0.497\n",
            "           snowboard        128          7      0.928      0.714      0.827       0.63\n",
            "         sports ball        128          6       0.68      0.667      0.708      0.433\n",
            "                kite        128         10      0.627        0.6      0.683      0.185\n",
            "        baseball bat        128          4      0.673          1      0.945      0.422\n",
            "      baseball glove        128          7       0.67      0.571      0.679      0.353\n",
            "          skateboard        128          5       0.75      0.601      0.766      0.431\n",
            "       tennis racket        128          7      0.868      0.714      0.718      0.372\n",
            "              bottle        128         18      0.774      0.763      0.769      0.498\n",
            "          wine glass        128         16      0.783      0.875      0.886      0.545\n",
            "                 cup        128         36      0.889      0.886      0.918      0.649\n",
            "                fork        128          6      0.693        0.5      0.714      0.448\n",
            "               knife        128         16      0.764      0.811      0.843      0.511\n",
            "               spoon        128         22       0.89      0.636      0.691      0.474\n",
            "                bowl        128         28      0.868      0.703      0.779      0.623\n",
            "              banana        128          1      0.786          1      0.995      0.597\n",
            "            sandwich        128          2     0.0996     0.0996      0.448      0.408\n",
            "              orange        128          4      0.542          1      0.995      0.713\n",
            "            broccoli        128         11      0.493      0.364      0.361      0.305\n",
            "              carrot        128         24      0.825      0.784      0.874      0.576\n",
            "             hot dog        128          2      0.565          1      0.995      0.995\n",
            "               pizza        128          5      0.899          1      0.995      0.751\n",
            "               donut        128         14      0.748          1      0.964      0.907\n",
            "                cake        128          4      0.713          1      0.995      0.908\n",
            "               chair        128         35      0.665      0.771      0.794      0.506\n",
            "               couch        128          6      0.712      0.667      0.792      0.598\n",
            "        potted plant        128         14       0.71      0.714      0.833      0.577\n",
            "                 bed        128          3          1      0.982      0.995      0.631\n",
            "        dining table        128         13      0.595      0.385      0.533       0.32\n",
            "              toilet        128          2       0.81          1      0.995      0.945\n",
            "                  tv        128          2      0.488          1      0.995      0.821\n",
            "              laptop        128          3      0.679      0.333       0.72       0.46\n",
            "               mouse        128          2          1          0      0.995      0.502\n",
            "              remote        128          8       0.85      0.625      0.752      0.628\n",
            "          cell phone        128          8      0.545      0.375      0.571      0.354\n",
            "           microwave        128          3      0.657          1      0.995      0.863\n",
            "                oven        128          5      0.536        0.6      0.615      0.465\n",
            "                sink        128          6      0.408      0.333      0.465      0.302\n",
            "        refrigerator        128          5       0.93        0.8      0.858      0.656\n",
            "                book        128         29      0.558      0.241      0.354      0.164\n",
            "               clock        128          9      0.947          1      0.995      0.778\n",
            "                vase        128          2      0.446          1      0.663      0.597\n",
            "            scissors        128          1      0.705          1      0.995     0.0995\n",
            "          teddy bear        128         21      0.852       0.55      0.911       0.58\n",
            "          toothbrush        128          5       0.91          1      0.995      0.789\n",
            "Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCIGcG0Mp4c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}